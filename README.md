
# üß† Sistema de Detecci√≥n de Secretos en C√≥digo Fuente mediante Fine-Tuning de LLMs

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marodero/tfm-secret-detector/blob/main/TFM_V1PLUS.ipynb)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![Model](https://img.shields.io/badge/Model-Qwen2.5--Coder--7B-violet?logo=huggingface&logoColor=white)](https://huggingface.co/Qwen/Qwen2.5-Coder-7B)
[![License](https://img.shields.io/badge/License-Apache%202.0-green)](LICENSE)

> **Trabajo Fin de M√°ster - Inteligencia Artificial Aplicada a la Ciberseguridad**
> *Autor: Miguel √Ångel Rodero Aguilar | Enero 2026*

---

## üìñ La Historia: Del "Detector de Metales" al "Auditor Experto"

Imagine un control de seguridad en un aeropuerto. Las herramientas tradicionales de detecci√≥n de secretos (como Gitleaks o TruffleHog) funcionan como un **detector de metales antiguo**: pitan cada vez que encuentran algo met√°lico. No distinguen entre un arma peligrosa y las llaves de casa. En el mundo del c√≥digo, esto genera miles de falsas alarmas ("fatiga de alertas") porque buscan **patrones r√≠gidos** (expresiones regulares).

**Este proyecto propone una evoluci√≥n:**

Hemos entrenado una Inteligencia Artificial para que act√∫e como un **Agente de Seguridad Experto**. Este modelo no busca patrones ciegamente; **lee, comprende el contexto y decide** si un fragmento de c√≥digo es realmente una credencial expuesta o simplemente una variable inofensiva.

### üéØ Lo que hemos conseguido
1.  **Comprensi√≥n Sem√°ntica:** El modelo distingue entre `API_KEY = "12345"` (Peligro üî¥) y `API_KEY = os.getenv("KEY")` (Seguro üü¢).
2.  **Cero Falsos Negativos:** En las pruebas, mientras las herramientas tradicionales dejaban pasar secretos complejos, nuestro modelo detect√≥ el **100%** de las amenazas reales.
3.  **Democratizaci√≥n:** Todo esto funciona en una GPU gratuita de Google Colab. No hacen falta superordenadores.

---

## üöÄ Gu√≠a de Reproducci√≥n para el Tribunal

He dise√±ado el c√≥digo (`TFM_V1PLUS.ipynb`) para que sea **aut√≥nomo, robusto y a prueba de fallos**. Puede ejecutarlo con total tranquilidad siguiendo estos pasos:

### 1. Abrir el Laboratorio
Haga clic en el bot√≥n **"Open in Colab"** al inicio de este documento o abra el archivo `.ipynb` incluido.

### 2. Configurar el Motor (GPU)
Para que la IA "piense" r√°pido, necesitamos activar la aceleraci√≥n por hardware:
* En el men√∫ superior de Colab: `Entorno de ejecuci√≥n` > `Cambiar tipo de entorno de ejecuci√≥n`.
* Seleccione **T4 GPU** (es gratuita y suficiente).

### 3. Ejecutar la Magia
Pulse `Ctrl + F9` o vaya a `Entorno de ejecuci√≥n` > `Ejecutar todas`.

---

## üõ°Ô∏è Mecanismo de Seguridad de Datos ("Safe Mode")

**¬øQu√© pasa si no tengo los datos originales?**
El entrenamiento original se realiz√≥ con el dataset *CredData* (Samsung), que reside en almacenamiento privado. Soy consciente de que usted, como evaluador, no tiene acceso a esos archivos.

**Soluci√≥n Implementada:**
El notebook incluye un sistema inteligente de detecci√≥n de entorno:
1.  Intenta buscar los datos reales en Google Drive.
2.  üö® **Si no los encuentra (su caso):** El c√≥digo lo detecta autom√°ticamente y activa el **"Modo Demostraci√≥n"**.
3.  **Generaci√≥n Sint√©tica:** El sistema crear√° al vuelo un dataset sint√©tico de alta calidad que imita los patrones reales.

> **Resultado:** Usted podr√° ejecutar el entrenamiento completo (Fine-Tuning con LoRA) de principio a fin, ver c√≥mo baja la curva de p√©rdida y probar el modelo, **sin necesidad de configurar ni descargar nada externo**.

---

## üî¨ Bajo el Cap√≥: Tecnolog√≠as Clave

Para lograr resultados profesionales con recursos limitados, hemos integrado lo mejor del estado del arte:

| Tecnolog√≠a | ¬øQu√© es? | ¬øQu√© conseguimos con ella? |
| :--- | :--- | :--- |
| **Qwen2.5-Coder** | El "Cerebro" | Un modelo Open Source que ya sabe programar. No empezamos de cero. |
| **Unsloth AI** | El "Acelerador" | Optimiza el entrenamiento haci√©ndolo 2x m√°s r√°pido y consumiendo menos memoria. |
| **QLoRA (4-bit)** | La "Compresi√≥n" | Nos permite cargar un modelo gigante (7B par√°metros) en una tarjeta gr√°fica peque√±a (16GB), sin perder inteligencia. |

---

## üìä Resultados de la Evaluaci√≥n (Anexo C)

Comparamos nuestro "Auditor IA" contra el est√°ndar de la industria (Gitleaks) en 25 casos de prueba complejos:

| M√©trica | Nuestro Modelo (IA) | Gitleaks (Regex) | An√°lisis |
| :--- | :---: | :---: | :--- |
| **Recall** | **100%** | 50% | **Seguridad Total.** La IA no dej√≥ escapar ning√∫n secreto. Gitleaks perdi√≥ la mitad. |
| **F1-Score** | **90,9%** | 66,7% | **Equilibrio.** La IA combina mejor la capacidad de encontrar secretos y evitar falsas alarmas. |

---

## üìÇ Estructura del Repositorio

* `TFM_V1PLUS.ipynb`: **El n√∫cleo del trabajo.** Notebook completo y documentado.
* `DOCUMENTO_TECNICO_V12.pdf`: Memoria t√©cnica detallada.
* `Detecci√≥n_de_Secretos_C√≥digo_Fuente_LLM.pdf`: Presentaci√≥n ejecutiva.
* `README.md`: Esta gu√≠a.

---

*Proyecto desarrollado con pasi√≥n por la ciberseguridad defensiva.*
*M√°ster en IA Aplicada a la Ciberseguridad - UCAM*

